{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Huawei for job.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3deea77c52b349a4a63a814e25f6d16b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_37064ac3f3294231aed6b847c6cbf5b6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7ea5475ec9004a019e3553f86f29db84",
              "IPY_MODEL_4bc507edfb7a46388f1c2d7966031fba"
            ]
          }
        },
        "37064ac3f3294231aed6b847c6cbf5b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7ea5475ec9004a019e3553f86f29db84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b2bc3da79ae44354b253d8e129a6f0e1",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 97935,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 97935,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1a355ff25d4b4c438d9b26a5a9e4c284"
          }
        },
        "4bc507edfb7a46388f1c2d7966031fba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6ff0fd3a59234bbbaeee935b345ad2b6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 97935/97935 [00:03&lt;00:00, 28044.42it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ac4c22f742a34c09ae8f98610ffcde50"
          }
        },
        "b2bc3da79ae44354b253d8e129a6f0e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1a355ff25d4b4c438d9b26a5a9e4c284": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6ff0fd3a59234bbbaeee935b345ad2b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ac4c22f742a34c09ae8f98610ffcde50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAFDWK0O8IV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# искать тексты примерно по 50-100 слов, надо будет посмотреть максимальный размер который поместиться в батч (50 слов в тестовом датасете)\n",
        "# лучше всего парсить литературу"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvGZqhPBviSf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVMdoe3spXO6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "209f9c42-64cf-4df6-c513-1afe740ee74b"
      },
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "import re\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import random\n",
        "import numpy as np\n",
        "from tqdm import tqdm_notebook, tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ol_f9ADbgIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/drive/My Drive/Huawei_for_job')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwI0AcnIpaq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data = pd.read_csv('/content/drive/My Drive/Huawei/data_rio.csv')\n",
        "#data = data.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d8xI0ucJ51X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#clean = data['text'].apply(lambda x: len(word_tokenize(str(x)))>70).values\n",
        "#data = data[clean]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVD6pZJfbimr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('./dataset.txt', 'r', encoding='utf-8') as f:\n",
        "  data = ''.join(f.readlines())"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_V15LOweRmW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_tokens = word_tokenize(data)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HKexFSSz8jz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('data_tokens.pickle', 'wb') as f:\n",
        "  pickle.dump(data_tokens, f)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwP5cFaAQfGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('data_tokens.pickle', 'rb') as f:\n",
        "  data_tokens = pickle.load(f)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBfe2OR_Qic7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LfOjn9cgX4E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5e2f512a-50ac-4f4b-c056-907e4de539b3"
      },
      "source": [
        "len(data_tokens)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29380485"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCMukQdDfcaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dataset(data, size = 300, download = True):\n",
        "  if download:\n",
        "    with open('data_tokens.pickle', 'rb') as f:\n",
        "        data_tokens = pickle.load(f)\n",
        "  else:\n",
        "    data_tokens = word_tokenize(data)\n",
        "\n",
        "  dataset = []\n",
        "  for i in tqdm_notebook(range(0, len(data_tokens), size)):\n",
        "    dataset.append(' '.join(data_tokens[i: i+size]))\n",
        "  return dataset"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qJUWs5Thbju",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "3deea77c52b349a4a63a814e25f6d16b",
            "37064ac3f3294231aed6b847c6cbf5b6",
            "7ea5475ec9004a019e3553f86f29db84",
            "4bc507edfb7a46388f1c2d7966031fba",
            "b2bc3da79ae44354b253d8e129a6f0e1",
            "1a355ff25d4b4c438d9b26a5a9e4c284",
            "6ff0fd3a59234bbbaeee935b345ad2b6",
            "ac4c22f742a34c09ae8f98610ffcde50"
          ]
        },
        "outputId": "5f5c8162-5138-4c86-b3b3-73faeba8996d"
      },
      "source": [
        "dataset = get_dataset(data)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3deea77c52b349a4a63a814e25f6d16b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=97935.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEHVcblGiOwk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2eb59ed1-6322-4dc4-e94d-f01de2ea6d41"
      },
      "source": [
        "len(dataset)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "97935"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VU7C9-hpwF0z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e1a7c75f-34e1-4a5a-9a1a-e3f35122410b"
      },
      "source": [
        "\"\"\"X = data['text'].apply(lambda x: ' '.join(filter(lambda x: x not in punctuation, word_tokenize(str(x)))))\n",
        "y = data['text'].apply(lambda x: str(x).lstrip())\n",
        "X = X.values\n",
        "y = y.values\"\"\""
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "\"X = data['text'].apply(lambda x: ' '.join(filter(lambda x: x not in punctuation, word_tokenize(str(x)))))\\ny = data['text'].apply(lambda x: str(x).lstrip())\\nX = X.values\\ny = y.values\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RxzOuOg7oOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#np.save('/content/drive/My Drive/y', y)\n",
        "#np.save('/content/drive/My Drive/X', X)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzDB_OEj8ogj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X = np.load('./X.npy', allow_pickle=True)\n",
        "#y = np.load('./y.npy', allow_pickle=True)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7eYjOBy1gkn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test = train_test_split(dataset, test_size = 0.1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQH-SzZLqBKR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from transformers import BertTokenizer, BertForMaskedLM\n",
        "\n",
        "#tokenizer = BertTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased\")\n",
        "#PAD = 0\n",
        "#MASK = 103\n",
        "#CLS = 101\n",
        "#SEP = 102\n",
        "#UNK = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Bg6cfqp1AIX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Tokenizer:\n",
        "  def __init__(self, full_data, vocab_size, lower = False, download = True):\n",
        "    if lower:\n",
        "      full_data = full_data.lower()\n",
        "\n",
        "    self.vocab_size = vocab_size\n",
        "    self.lower = lower\n",
        "    if download:\n",
        "      with open('tokenizer_vocab.pickle', 'rb') as f:\n",
        "        self.vocab = pickle.load(f)\n",
        "    else:\n",
        "        tokens = word_tokenize(full_data, language='russian')\n",
        "        self.vocab = pd.Series(nltk.FreqDist(tokens)).sort_values(ascending=False)[:self.vocab_size-1].index\n",
        "\n",
        "    self.converter = preprocessing.LabelEncoder()\n",
        "    self.converter.fit(self.vocab.tolist() + ['unk'])\n",
        "    self.classes = self.converter.classes_\n",
        "    self.unk = self.converter.transform(['unk'])[0]\n",
        "  \n",
        "  def convert_to_ids(self, input):\n",
        "    if self.lower:\n",
        "      input = input.lower()\n",
        "\n",
        "    input = word_tokenize(input)\n",
        "    ids = []\n",
        "    for word in input:\n",
        "      if word in self.classes:\n",
        "        ids += self.converter.transform([word]).tolist()\n",
        "      else:\n",
        "        ids += [self.unk]\n",
        "    \n",
        "    return ids\n",
        "\n",
        "  def convert_to_subwords(self, ids):\n",
        "    return self.converter.inverse_transform(ids)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8DlDgM3HDLT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(data, 50000)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPOcMYcPjL_8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "da3c2688-60f6-49a7-fd51-d6dc00daf67a"
      },
      "source": [
        "tokenizer.convert_to_ids('vdjfvn.lcm;se')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1171, 53, 1030]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kfME-cV51iS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80276f99-69c9-49e5-8bf1-7e264f3a597c"
      },
      "source": [
        "#сделать поменьше список только из самых нужных знаков препинания\n",
        "punctuation = string.punctuation\n",
        "punctuation_set = set('!,.-?:;')\n",
        "#punctuation = set(string.punctuation)\n",
        "nothing = ''\n",
        "#padding = 'PAD'\n",
        "labels = [nothing] + list(punctuation_set)\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(labels)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelEncoder()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGExY8kZ3YO1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertConfig\n",
        "\n",
        "config = BertConfig(\n",
        "                    vocab_size=tokenizer.vocab_size,\n",
        "                    encoder_layers = 3,\n",
        "                    decoder_layers = 3\n",
        "                    )"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8EqpDaCCJTc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertForMaskedLM\n",
        "\n",
        "class BertPunc(nn.Module):  \n",
        "    \n",
        "    def __init__(self, dropout, seq_len = 50):\n",
        "        super(BertPunc, self).__init__()\n",
        "        self.bert = BertForMaskedLM(config)\n",
        "        self.bert_vocab_size = tokenizer.vocab_size\n",
        "        self.bn = nn.BatchNorm1d(seq_len)\n",
        "        self.fc = nn.Linear(self.bert_vocab_size, len(labels))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input_ids = None, attention_mask = None, token_type_ids = None):\n",
        "        x = self.bert(input_ids = input_ids,\n",
        "                      attention_mask = attention_mask,\n",
        "                      token_type_ids = token_type_ids)\n",
        "        x = self.fc(self.dropout(self.bn(x[0])))\n",
        "        return x"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5WRACHQ6alG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('target_train.pickle', 'wb') as f:\n",
        "  dataset = []\n",
        "  for row in X_train:\n",
        "    dataset.append(word_tokenize(row))\n",
        "  pickle.dump(dataset, f)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNk0KfV17IsB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('target_test.pickle', 'wb') as f:\n",
        "  dataset = []\n",
        "  for row in X_test:\n",
        "    dataset.append(word_tokenize(row))\n",
        "  pickle.dump(dataset, f)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibxBkYbu8u1T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('data_train.pickle', 'wb') as f:\n",
        "  dataset = []\n",
        "  for row in X_train:\n",
        "    dataset.append(' '.join(list(filter(lambda x: x not in punctuation, word_tokenize(row)))))\n",
        "  pickle.dump(dataset, f)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7ynhWS187sM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('data_test.pickle', 'wb') as f:\n",
        "  dataset = []\n",
        "  for row in X_test:\n",
        "    dataset.append(' '.join(list(filter(lambda x: x not in punctuation, word_tokenize(row)))))\n",
        "  pickle.dump(dataset, f)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAVCY3mgPnGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('data_train.pickle', 'rb') as f:\n",
        "  data = pickle.load(f)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2M8IaCO0Q4TE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('target_test.pickle', 'rb') as f:\n",
        "  target = pickle.load(f)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cvD5EJfR06S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def r():\n",
        "  x = tokenizer.convert_to_ids(data[0])[:50]\n",
        "  token_type, attn = [0]*len(x), [1]*len(x)\n",
        "  tokens = target[0]\n",
        "  labels = []\n",
        "  j = 0\n",
        "  i = 0\n",
        "  while i < len(tokens)-1:\n",
        "    if tokens[i+1] in punctuation_set:\n",
        "      labels.append(tokens[i+1])\n",
        "      i += 2\n",
        "    else:\n",
        "      labels.append('')\n",
        "      i += 1  \n",
        "  labels = le.transform(labels).tolist()[:50]\n",
        "  x = torch.tensor(x, dtype = torch.long)\n",
        "  attention_mask = torch.tensor(attn)\n",
        "  labels = torch.tensor(labels, dtype = torch.long)\n",
        "  token_type = torch.tensor(token_type)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGW-bJuE18GD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def punc_check(data):\n",
        "  dataset = []\n",
        "  for row in data:\n",
        "    dataset.append(' '.join(list(filter(lambda x: x not in punctuation, word_tokenize(row)))))\n",
        "  return dataset\n",
        "\n",
        "class Punctuation(Dataset):\n",
        "  def __init__(self, X, max_len = 50, mode = 'train'):\n",
        "    #self.data = punc_check(X)\n",
        "    self.max_len = max_len\n",
        "    if mode == 'train':\n",
        "      with open('target_train.pickle', 'rb') as f:\n",
        "        self.target = pickle.load(f)\n",
        "      \n",
        "      with open('data_train.pickle', 'rb') as f:\n",
        "        self.data = pickle.load(f)\n",
        "\n",
        "      \n",
        "    else:\n",
        "      with open('target_test.pickle', 'rb') as f:\n",
        "        self.target = pickle.load(f)\n",
        "\n",
        "      with open('data_test.pickle', 'rb') as f:\n",
        "        self.data = pickle.load(f)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "    indexes = tokenizer.convert_to_ids(' '.join(word_tokenize(self.data[idx])[:self.max_len]))\n",
        "    if len(indexes) == self.max_len:\n",
        "      x = indexes\n",
        "    else:\n",
        "      x = tokenizer.convert_to_ids(self.data[idx])[:self.max_len]\n",
        "    token_type, attn = [0]*len(x), [1]*len(x)\n",
        "    tokens = self.target[idx]\n",
        "    labels = []\n",
        "    i = 0\n",
        "\n",
        "    while i < len(tokens)-1:\n",
        "      if tokens[i+1] in punctuation_set:\n",
        "        labels.append(tokens[i+1])\n",
        "        i += 2\n",
        "      else:\n",
        "        labels.append('')\n",
        "        i += 1\n",
        "    \n",
        "    labels = le.transform(labels).tolist()[:self.max_len]\n",
        "    if len(labels) != len(x) != self.max_len:\n",
        "      print(self.data[idx])\n",
        "      print(len(labels))\n",
        "    assert len(labels) == len(x) == self.max_len\n",
        "    \n",
        "    x = torch.tensor(x, dtype = torch.long)\n",
        "    attention_mask = torch.tensor(attn)\n",
        "    labels = torch.tensor(labels, dtype = torch.long)\n",
        "    token_type = torch.tensor(token_type)\n",
        "    #tokens = ' '.join(tokens[:self.max_len])\n",
        "\n",
        "    return x, attention_mask, token_type, labels"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTkBaqFV98sV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"def collate_fn(records):\n",
        "  max_len_input = 52\n",
        "  max_len_target = 50\n",
        "  attention_mask = torch.zeros(len(records), max_len_input)\n",
        "  target = torch.ones(len(records), max_len_target)*int(le.transform(['PAD']))\n",
        "  input = torch.zeros(len(records), max_len_input)\n",
        "  token_types = torch.zeros(len(records), max_len_input)\n",
        "\n",
        "  for i, record in enumerate(records):\n",
        "    len_ = min(max_len_input, len(record['input']))\n",
        "    input[i, :len_] += record['input'][:len_]\n",
        "\n",
        "    target[i][target[i]==0] = 1\n",
        "    target[i, :len(record['labels'])] += record['labels']\n",
        "    target[i][target[i]==24] = 0\n",
        "\n",
        "    \n",
        "    attention_mask[i, :len_] += record['attention_mask'][:len_]\n",
        "\n",
        "  return {'input_ids':input,\n",
        "          'attention_mask':attention_mask,\n",
        "          'token_type_ids':token_types,\n",
        "          'decoder_input_ids':target}\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kM3XPPsX9gjq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = Punctuation(X_train)\n",
        "#inp, attn, types, lab = next(iter(DataLoader(train_dataset, batch_size=100, shuffle=True)))"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1niDwqmd-M1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inp, attn, types, lab = next(iter(DataLoader(train_dataset, batch_size=3, shuffle=True)))"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJIykNi1iF6J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d7763f7b-f0c8-47ca-ca50-753e09d37fd0"
      },
      "source": [
        "inp.shape, lab.shape"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 50]), torch.Size([3, 50]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuQ7dk1adBir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from utils import check_one\n",
        "\n",
        "def check_metric(input, attn, types, reference):\n",
        "  model.eval()\n",
        "  hypothesis_1 = le.inverse_transform(model(input, attn, types).squeeze().argmax(dim=-1))\n",
        "  hypothesis = tokenizer.convert_ids_to_tokens(inp.squeeze())\n",
        "\n",
        "  i = 0\n",
        "  j = 0\n",
        "  while i<len(hypothesis):\n",
        "    hypothesis.insert(i+1, hypothesis_1[j])\n",
        "    i += 2\n",
        "    j += 1\n",
        "  \n",
        "  hypothesis = ' '.join(hypothesis)\n",
        "\n",
        "  return check_one(reference[0], hypothesis)\n",
        "\n",
        "def check_metric_epoch(inputs, attns, types, references):\n",
        "  metrics = [check_metric(*batch) for batch in zip(inputs, attns, types, references)]\n",
        "  return torch.tensor(metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38LiNI1fh9SY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "check_metric_epoch(inp, attn, types, ref)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhFTkbp49vhG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, dataloader, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    epoch_loss = 0.\n",
        "    metrics = 0.\n",
        "    with tqdm(desc=\"epoch\", total=len(dataloader)) as pbar_outer:\n",
        "      for batch in dataloader:\n",
        "\n",
        "          optimizer.zero_grad()     \n",
        "\n",
        "          x, attn, types, labels = batch    \n",
        "          x = x.to(device)\n",
        "          attn = attn.to(device)\n",
        "          types = types.to(device)\n",
        "          labels = labels.to(device)             \n",
        "          \n",
        "          outputs = model(x, attn, types)\n",
        "          \n",
        "          loss = criterion(outputs.view(-1, outputs.shape[-1]), labels.view(-1))\n",
        "          \n",
        "          loss.backward()\n",
        "          \n",
        "          torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "          \n",
        "          optimizer.step()\n",
        "          \n",
        "          epoch_loss += loss.item()\n",
        "\n",
        "          pbar_outer.update(1)\n",
        "          tqdm.write(\"train_loss:{}\".format(loss.item()))\n",
        "        \n",
        "    train_loss = round( (epoch_loss / len(dataloader)), 3)\n",
        "        \n",
        "    return train_loss"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TJoakJfBWP7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, dataloader, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    metrics = 0.\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      with tqdm(desc=\"epoch\", total=len(dataloader)) as pbar_outer:\n",
        "        for batch in tqdm_notebook(dataloader, total=len(dataloader)):\n",
        "\n",
        "            x, attn, types, labels = batch    \n",
        "            x = x.to(device)\n",
        "            attn = attn.to(device)\n",
        "            types = types.to(device)\n",
        "            labels = labels.to(device)             \n",
        "            \n",
        "            outputs = model(x, attn, types)\n",
        "        \n",
        "            loss = criterion(outputs.view(-1, outputs.shape[-1]), labels.view(-1))\n",
        "            \n",
        "            epoch_loss += loss.item()\n",
        "            \n",
        "            pbar_outer.update(1)\n",
        "            tqdm.write(\"val_loss:{}\".format(loss.item()))\n",
        "            \n",
        "        valid_loss = round((epoch_loss / len(dataloader)), 3)\n",
        "  \n",
        "    return valid_loss"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oDw53P1BYmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "device = torch.device('cuda')\n",
        "#metrics = -100\n",
        "\n",
        "model = BertPunc(0.3).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-5)\n",
        "train_dl = DataLoader(Punctuation(X_train), batch_size=16)\n",
        "val_dl = DataLoader(Punctuation(X_test), batch_size=16)\n",
        "\n",
        "clip = 3\n",
        "num_epochs = 50\n",
        "best_loss = 100\n",
        "history_val = []\n",
        "history_train = []\n",
        "\n",
        "for epoch in tqdm_notebook(range(num_epochs)):\n",
        "  \n",
        "  train_loss = train(model, train_dl, optimizer, criterion, clip)\n",
        "  valid_loss = evaluate(model, val_dl, criterion)\n",
        "\n",
        "  history_val.append(valid_loss)\n",
        "  history_train.append(train_loss)\n",
        "\n",
        "  clear_output(True)\n",
        "  plt.plot(history_train, label = 'train_loss')\n",
        "  plt.plot(history_val, label = 'valid_loss')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  print('Epoch: {} \\n Train Loss {}  Val loss {}'.format(epoch + 1, train_loss, valid_loss))\n",
        "\n",
        "  if valid_loss < best_loss:\n",
        "    best_loss = valid_loss\n",
        "    torch.save(model.state_dict(), 'puncBert.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbpWKyweCGt6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "5f069728-312a-415d-e54d-9141cd21491b"
      },
      "source": [
        "model(inp.to(device), attn.to(device), types.to(device)).argmax(dim=-1)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5UbTW-NLTRS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "21aae773-c5dc-435a-a54a-358b8697a247"
      },
      "source": [
        "lab"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 4, 0, 0, 0, 0,\n",
              "         0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0,\n",
              "         2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 2, 7, 2, 0, 0, 0, 0, 4, 0, 0, 0, 0,\n",
              "         0, 0],\n",
              "        [0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 2, 2, 0, 0, 0,\n",
              "         0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0,\n",
              "         0, 2]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7pUIfUvehSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "st = 'ете “ был хуже .Читательница Наталья Душина из г. Кологрива Костромской губернии приславшая Чехову в г. несколько восторженных писем писала ему в марте г. по поводу достоверности чеховских персонажей И „Муж “ в Вашем рассказе мне знаком тупой злой и страшный .Н К. Михайловский после выхода I тома издания А. Ф. Маркса отметив однообразие помещенных там рассказов молодого Чехова забавно и добродушно-примирительно излагающих отнюдь не смешные ситуации преимущественно супружеской жизни выделил из них только рассказ Муж как нечто довольно исключительное в сборнике г. Чехова — исключительное не по сюжету а по тону каким говорит автор Здесь по словам Михайловского автор и сам не смеется и не желает возбуждать смех в читателе Читатель переполняется ощущением жути и воспринимает героев как жертвы беспробудной пошлости жизни Принципиально иное отношение Чехова к изображаемому по мнению Михайловского обусловило в Муже и высокую степень истинно художественного творчества художественные приемы Чехова в этом рассказе показались критику более тонкими по сравнению с другими и он расценил его как настоящий перл в художественном отношении Выдающимися сценами по манере изображения он считал пляску Анны Павловны с черным неуклюжим и скуластым офицером кроме танцев ни на что не пригодным и затем изображение разгорающегося недовольства мужа переходящего в гнев по поводу веселости жены верхом совершенства представилась Михайловскому заключительная сцена в собрании когда Анна Павловна шёпотом умоляет мужа остаться еще на этом танцевальном вечере Эту поэзию контрастов и нотки гнева или хотя бы недовольства Михайловский не видел в других рассказах на сходные темы от которых Муж отличается более глубоким настроением Михайловский находил что тенденции проявившиеся в Муже со временем набирают силу и всё чаще'\n"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o24w7l1aj30p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}